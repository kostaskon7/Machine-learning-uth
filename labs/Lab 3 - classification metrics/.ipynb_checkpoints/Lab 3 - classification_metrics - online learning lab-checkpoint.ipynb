{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "Konstantinos Konstantinidis AEM:2546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a classification model\n",
    "\n",
    "\\begin{exercise}\n",
    "Evaluate the Naive Bayes classification model for the `titanic_trainc.csv` dataset by applying the following  classification metrics, and summarize the performance of the model. \n",
    "\n",
    "\\end{exercise}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by **changing the classification threshold**?\n",
    "- What is the purpose of an **ROC curve**?\n",
    "- How does **Area Under the Curve (AUC)** differ from classification accuracy?\n",
    "- what is Kfold verification method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy\n",
    "\n",
    "[Pima Indians Diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) originally from the UCI Machine Learning Repository\n",
    "\n",
    "# Column Data desctiption\n",
    "    pregnancies - Number of times pregnant\n",
    "    \n",
    "    Glucose - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "    \n",
    "    BloodPressure - Diastolic blood pressure (mm Hg)\n",
    "    \n",
    "    SkinThickness - Triceps skin fold thickness (mm)\n",
    "    \n",
    "    Insulin - 2-Hour serum insulin (mu U/ml)\n",
    "    \n",
    "    BMI - Body mass index (weight in kg/(height in m)^2)\n",
    "    \n",
    "    DiabetesPedigreeFunction - Diabetes pedigree function\n",
    "    \n",
    "    Age - Age (years)\n",
    "    \n",
    "    Outcome - Class variable (0 or 1) class value 1 is interpreted as \"tested positive for diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a pandas DataFrame\n",
    "import pandas as pd\n",
    "path = 'titanic_train.csv'\n",
    "col_names = ['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\n",
    "pima = pd.read_csv(path, header=0,names=col_names)\n",
    "pima.columns = [\"V\"+str(i) for i in range(1, len(pima.columns)+1)]  # rename column names to be similar to R naming convention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3                                                 V4      V5  \\\n",
       "0   1   0   3                            Braund, Mr. Owen Harris    male   \n",
       "1   2   1   1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2   3   1   3                             Heikkinen, Miss. Laina  female   \n",
       "3   4   1   1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4   5   0   3                           Allen, Mr. William Henry    male   \n",
       "\n",
       "     V6  V7  V8                V9      V10   V11 V12  \n",
       "0  22.0   1   0         A/5 21171   7.2500   NaN   S  \n",
       "1  38.0   1   0          PC 17599  71.2833   C85   C  \n",
       "2  26.0   0   0  STON/O2. 3101282   7.9250   NaN   S  \n",
       "3  35.0   1   0            113803  53.1000  C123   S  \n",
       "4  35.0   0   0            373450   8.0500   NaN   S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    V1  V3   V4  V5    V6  V7  V8   V9  V10   V11  V12\n",
      "0    0   2  108   1  21.0   1   0  523  174  76.0  2.0\n",
      "1  111   0  190   0  45.0   1   0  596  199  81.0  0.0\n",
      "2  222   2  353   0  27.0   0   0  669  197  76.0  2.0\n",
      "3  333   0  272   0  41.0   1   0   49  142  55.0  2.0\n",
      "4  444   2   15   1  41.0   0   0  472  211  76.0  2.0\n",
      "\\\\\\\\\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: V2, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ord_enc = LabelEncoder()\n",
    "\n",
    "X_numerical=pd.DataFrame()\n",
    "data_numerical=pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(2,len(pima.columns)+1):\n",
    "    temp=\"V\"+str(i)\n",
    "    data_numerical[temp]=ord_enc.fit_transform(pima[temp].astype(str))\n",
    "\n",
    "data_numerical[\"V1\"]=ord_enc.fit_transform(pima[\"V1\"].astype(str))  \n",
    "\n",
    "data_numerical=data_numerical.where(~pima.isna(),pima)\n",
    "\n",
    "data_numerical=data_numerical.fillna(value=data_numerical.mean())\n",
    "\n",
    "data_numerical\n",
    "\n",
    "X = data_numerical.loc[:,[ \"V1\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\"]]\n",
    "y = data_numerical.V2\n",
    "print(X.head())\n",
    "print(\"\\\\\\\\\\\\\\\\\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = GNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7802690582959642\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    139\n",
       "1     84\n",
       "Name: V2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37668161434977576"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6233183856502242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6233183856502242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.623318\n",
       "Name: V2, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0]\n",
      "Pred: [0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/AOIkPnKu0YA/maxresdefault.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  33]\n",
      " [ 16  68]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [0 1 0]\n",
      " [1 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.50      0.50      0.50         2\n",
      "           b       0.50      1.00      0.67         1\n",
      "           c       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.67      0.67      0.61         5\n",
      "weighted avg       0.70      0.60      0.60         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the dependancies\n",
    "from sklearn import metrics\n",
    "# Predicted values\n",
    "y_pred = [\"a\", \"b\", \"c\", \"a\", \"b\"]\n",
    "# Actual values\n",
    "y_act = [\"a\", \"b\", \"c\", \"c\", \"a\"]\n",
    "# Printing the confusion matrix\n",
    "# The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "print(metrics.confusion_matrix(y_act, y_pred, labels=[\"a\", \"b\", \"c\"]))\n",
    "# Printing the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_act, y_pred, labels=[\"a\", \n",
    "\"b\",\"c\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0]\n",
      "Pred: [0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](images/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "**Classification Accuracy:** Overall, how often is the classifier correct?\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*5XuZ_86Rfce3qyLt7XMlhw.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7802690582959642\n",
      "0.7802690582959642\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When to use Accuracy:\n",
    "\n",
    "Accuracy is a good measure when the target variable classes in the data are nearly balanced. example (60% yes - 40% no)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error \n",
    "\n",
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21973094170403587\n",
      "0.21973094170403584\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Precision is defined as the number of true positives divided by the number of true positives plus the number of false positives.\n",
    "Precision is about being precise\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/640/1*KhlD7Js9leo0B0zfsIfAIA.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6732673267326733\n"
     ]
    }
   ],
   "source": [
    "print(TP/float(TP+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall or Sensitivity\n",
    "\n",
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\"\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/640/1*a8hkMGVHg3fl4kDmSIDY_A.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095238095238095\n",
      "0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity\n",
    "\n",
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762589928057554\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate\n",
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23741007194244604\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score\n",
    "\n",
    "F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, <b style=\"color:red\">especially if you have an uneven class distribution</b>\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UJxVqLnbSj42eRhasKeLOA.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the classification threshold\n",
    "### Probability Predictions\n",
    "Another type of prediction you may wish to make is the probability of the data instance belonging to each class.\n",
    "\n",
    "This is called a probability prediction where given a new instance, the model returns the probability for each outcome class as a value between 0 and 1.\n",
    "\n",
    "You can make these types of predictions in scikit-learn by calling the `predict_proba()` function, for example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted responses\n",
    "GNB.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.33019433e-01, 2.66980567e-01],\n",
       "       [9.73253459e-01, 2.67465410e-02],\n",
       "       [9.99977945e-01, 2.20545802e-05],\n",
       "       [4.13867790e-03, 9.95861322e-01],\n",
       "       [4.62583140e-02, 9.53741686e-01],\n",
       "       [4.34689599e-01, 5.65310401e-01],\n",
       "       [4.85064345e-02, 9.51493566e-01],\n",
       "       [5.30764063e-02, 9.46923594e-01],\n",
       "       [2.91468606e-02, 9.70853139e-01],\n",
       "       [6.71991429e-02, 9.32800857e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "GNB.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Row: observation\n",
    "\n",
    "    - Each row, numbers sum to 1\n",
    "    \n",
    "* Column: class\n",
    "\n",
    "  - 2 response classes there 2 columns\n",
    "    \n",
    "       - column 0: predicted probability that each observation is a member of class 0\n",
    "       \n",
    "       - column 1: predicted probability that each observation is a member of class 1\n",
    "       \n",
    "* Importance of predicted probabilities\n",
    "    - We can rank observations by probability of diabetes\n",
    "        - Prioritize contacting those with a higher probability\n",
    "\n",
    "* predict_proba process\n",
    "\n",
    "    1. Predicts the probabilities\n",
    "    \n",
    "    2. Choose the class with the highest probability\n",
    "\n",
    "* There is a 0.5 classification threshold\n",
    "\n",
    "    - Class 1 is predicted if probability > 0.5\n",
    "    \n",
    "    - Class 0 is predicted if probability < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.66980567e-01, 2.67465410e-02, 2.20545802e-05, 9.95861322e-01,\n",
       "       9.53741686e-01, 5.65310401e-01, 9.51493566e-01, 9.46923594e-01,\n",
       "       9.70853139e-01, 9.32800857e-01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities for class 1\n",
    "GNB.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = GNB.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see from the third bar\n",
    "\n",
    "    - Most  of observations have probability < 0.5\n",
    "    \n",
    "    - Small number of observations with probability > 0.5\n",
    "    \n",
    "    - This is below the threshold of 0.5\n",
    "    \n",
    "    - Most would be predicted \"no diabetes\" in this case\n",
    "    \n",
    "* Solution\n",
    "\n",
    "    - **Decrease the threshold**  for predicting diabetes\n",
    "    \n",
    "        - Increase the sensitivity of the classifier\n",
    "        \n",
    "            - This would increase the number of TP\n",
    "            \n",
    "            - More sensitive to positive instances\n",
    "            \n",
    "            - Example of metal detector\n",
    "            \n",
    "                - Threshold set to set off alarm for large object but not tiny objects\n",
    "                \n",
    "                - YES: metal, NO: no metal\n",
    "                \n",
    "                - We lower the threshold amount of metal to set it off\n",
    "                \n",
    "                - It is now more sensitive to metal\n",
    "                \n",
    "                - It will then predict YES more often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass threshold=0.3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.66980567e-01, 2.67465410e-02, 2.20545802e-05, 9.95861322e-01,\n",
       "       9.53741686e-01, 5.65310401e-01, 9.51493566e-01, 9.46923594e-01,\n",
       "       9.70853139e-01, 9.32800857e-01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted classes with the lower threshold\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  33]\n",
      " [ 16  68]]\n"
     ]
    }
   ],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 41]\n",
      " [13 71]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The row totals are the same\n",
    "\n",
    "* The rows represent actual response values\n",
    "\n",
    "      - 130 values top row\n",
    "      \n",
    "      - 62 values bottom row\n",
    "      \n",
    "Observations from the left column moving to the right column because we will have more TP and FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5967741935483871\n"
     ]
    }
   ],
   "source": [
    "# sensitivity has increased (used to be 0.24)\n",
    "print(37 / float(25 + 37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "# specificity has decreased (used to be 0.91)\n",
    "print(92 / float( 92+ 38))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be **adjusted** to increase sensitivity or specificity\n",
    "- Sensitivity and specificity have an **inverse relationship**\n",
    "- Adjusting the threshold should be one of the last step you do in the model-building process\n",
    "     - The most important steps are\n",
    "     - Building the models\n",
    "     - Selecting the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8095238095238095\n",
      "Specificity: 0.7697841726618705\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8452380952380952\n",
      "Specificity: 0.7266187050359711\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490065090784515\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC is useful as a **single number summary** of classifier performance.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Kostas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8244458591517414"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a **variety of metrics**\n",
    "- Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to **set a classification threshold**\n",
    "- Still useful when there is **high class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "## KFOLD\n",
    "\n",
    "In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*me-aJdjnt3ivwAurYkB7PA.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{exercise}\n",
    "Implement the KFOLD method for the above dataset using sklearn\n",
    "\n",
    "\\end{exercise}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Resources\n",
    "\n",
    "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by me\n",
    "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
    "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
    "- Graphic: How [classification threshold](https://media.amazonwebservices.com/blog/2015/ml_adjust_model_1.png) affects different evaluation metrics (from a [blog post](https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/) about Amazon Machine Learning)\n",
    "\n",
    "\n",
    "## ROC and AUC Resources\n",
    "\n",
    "- Video: [ROC Curves and Area Under the Curve](https://www.youtube.com/watch?v=OAl6eAyP-yo) (14 minutes) by me, including [transcript and screenshots](http://www.dataschool.io/roc-curves-and-auc-explained/) and a [visualization](http://www.navan.name/roc/)\n",
    "- Video: [ROC Curves](https://www.youtube.com/watch?v=21Igj5Pr6u4) (12 minutes) by Rahul Patwari\n",
    "- Paper: [An introduction to ROC analysis](http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf) by Tom Fawcett\n",
    "- Usage examples: [Comparing different feature sets](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf) for detecting fraudulent Skype users, and [comparing different classifiers](http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Bradley_PR97.pdf) on a number of popular datasets\n",
    "\n",
    "## Other Resources\n",
    "\n",
    "- scikit-learn documentation: [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Guide: [Comparing model evaluation procedures and metrics](https://github.com/justmarkham/DAT8/blob/master/other/model_evaluation_comparison.md) by me\n",
    "- Video: [Counterfactual evaluation of machine learning models](https://www.youtube.com/watch?v=QWCSxAKR-h0) (45 minutes) about how Stripe evaluates its fraud detection model, including [slides](http://www.slideshare.net/MichaelManapat/counterfactual-evaluation-of-machine-learning-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
